{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/amanjain1397/zip-the-code-1.0/blob/master/v_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "7Pwq9fDJu2sG",
    "outputId": "efb82fad-dcd0-433b-aabd-e71563fe3419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "Selecting previously unselected package google-drive-ocamlfuse.\n",
      "(Reading database ... 131323 files and directories currently installed.)\n",
      "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
      "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "# Generate auth tokens for Colab\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Generate creds for the Drive FUSE library.\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CmLSEOyhu7oS",
    "outputId": "ed53083e-afb0-4b39-d90e-844446f81651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tTl_vxGPvplJ",
    "outputId": "67df0847-e338-41db-8d4f-24b14f8d2f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/DL/Keras - Text\n"
     ]
    }
   ],
   "source": [
    "cd drive/DL/Keras - Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "sVa2BcBlvqCU",
    "outputId": "38fb0d54-351e-411a-bb4b-6faf29de34eb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import keras\n",
    "\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvx0EdUFvsqf"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    #Lowering case the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Removing numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    #Removing punctuations\n",
    "    import string\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    #Removing stop words\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([ i for i in tokens if not i in stopwords])\n",
    "    \n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Eoq0CcnvMV_G",
    "outputId": "ffc8f45c-4a52-4321-cfb0-73dae0f94b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36088 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/train_file.csv')\n",
    "test = pd.read_csv('./data/test_file.csv')\n",
    "sample = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "data.loc[data.Subjects.isnull(), 'Subjects'] = ''\n",
    "test.loc[test.Subjects.isnull(), 'Subjects'] = ''\n",
    "\n",
    "data['combined'] = data.Subjects.str.cat(' ' + data.Title)\n",
    "test['combined'] = test.Subjects.str.cat(' ' + test.Title)\n",
    "\n",
    "dataMatType = data.MaterialType\n",
    "data.drop(labels = ['MaterialType'], axis = 1, inplace = True)\n",
    "\n",
    "data.combined = data.combined.apply(preprocess_text)\n",
    "test.combined = test.combined.apply(preprocess_text)\n",
    "'''\n",
    "data.Subjects = data.Subjects.apply(preprocess_text)\n",
    "data.Title = data.Title.apply(preprocess_text)\n",
    "test.Subjects = test.Subjects.apply(preprocess_text)\n",
    "test.Title = test.Title.apply(preprocess_text)\n",
    "'''\n",
    "flag = -1\n",
    "labelDict = {}\n",
    "\n",
    "for key in dataMatType.value_counts().keys():\n",
    "  flag += 1\n",
    "  labelDict[key] = flag\n",
    "  \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 10                             \n",
    "\n",
    "max_words = 1000                                    \n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data.combined)\n",
    "\n",
    "dataSequences = tokenizer.texts_to_sequences(data.combined)\n",
    "testSequences = tokenizer.texts_to_sequences(test.combined)\n",
    "\n",
    "data_word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(data_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmgGkE7lvwc0"
   },
   "outputs": [],
   "source": [
    "from keras import preprocessing\n",
    "x_train = preprocessing.sequence.pad_sequences(dataSequences, maxlen = 10)\n",
    "x_test = preprocessing.sequence.pad_sequences(testSequences, maxlen = 10)\n",
    "\n",
    "train_label = dataMatType.map(labelDict)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "labelDataBinary = to_categorical(train_label)\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(dataMatType), dataMatType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PFlbzeBoGMX9",
    "outputId": "4939380c-9475-4ef0-ce05-17503f4d005d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open( './glove.6B/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_dim = 300\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in data_word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "p8lV4j7qvUNd",
    "outputId": "a1af66d0-3193-4146-db31-ba67cc269cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25322 samples, validate on 6331 samples\n",
      "Epoch 1/8\n",
      "25322/25322 [==============================] - 58s 2ms/step - loss: 0.5827 - acc: 0.8373 - val_loss: 0.4636 - val_acc: 0.8727\n",
      "Epoch 2/8\n",
      "25322/25322 [==============================] - 50s 2ms/step - loss: 0.4632 - acc: 0.8698 - val_loss: 0.4404 - val_acc: 0.8785\n",
      "Epoch 3/8\n",
      "25322/25322 [==============================] - 50s 2ms/step - loss: 0.4425 - acc: 0.8743 - val_loss: 0.4657 - val_acc: 0.8789\n",
      "Epoch 4/8\n",
      "25322/25322 [==============================] - 49s 2ms/step - loss: 0.4271 - acc: 0.8776 - val_loss: 0.4289 - val_acc: 0.8807\n",
      "Epoch 5/8\n",
      "25322/25322 [==============================] - 49s 2ms/step - loss: 0.4190 - acc: 0.8805 - val_loss: 0.4479 - val_acc: 0.8782\n",
      "Epoch 6/8\n",
      "25322/25322 [==============================] - 49s 2ms/step - loss: 0.4146 - acc: 0.8804 - val_loss: 0.4816 - val_acc: 0.8837\n",
      "Epoch 7/8\n",
      "25322/25322 [==============================] - 49s 2ms/step - loss: 0.4115 - acc: 0.8822 - val_loss: 0.4838 - val_acc: 0.8833\n",
      "Epoch 8/8\n",
      "25322/25322 [==============================] - 49s 2ms/step - loss: 0.4020 - acc: 0.8838 - val_loss: 0.4494 - val_acc: 0.8820\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 300, input_length=10))\n",
    "\n",
    "'''model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "'''\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 3,  activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(400, recurrent_dropout = 0.6, return_sequences = True))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(LSTM(400, recurrent_dropout = 0.2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, labelDataBinary,\n",
    "                    epochs=8,\n",
    "                    validation_split=0.2,\n",
    "                    class_weight = class_weights)\n",
    "\n",
    "model.save('./models/m5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-vJg1_cvU9W"
   },
   "outputs": [],
   "source": [
    "model.save('./models/m1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8EGozWZ3UdC"
   },
   "source": [
    "**Using Embedding Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNdQiMIGwjQD"
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 300, input_length=10, weights=[embedding_matrix], trainable=False))\n",
    "\n",
    "'''model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "'''\n",
    "\n",
    "model.add(LSTM(1000, recurrent_dropout = 0.3))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, labelDataBinary,\n",
    "                    epochs=8,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZReVSR3gy5kI"
   },
   "outputs": [],
   "source": [
    "reverseLabelDict = {}\n",
    "\n",
    "for key, value in labelDict.items():\n",
    "  reverseLabelDict[value] = key\n",
    "  \n",
    "predictions = model.predict(x_test)\n",
    "predictions = pd.Series([np.argmax(i) for i in predictions], index = test.index)\n",
    "predictions = predictions.map(reverseLabelDict)\n",
    "\n",
    "submission = pd.concat([test.ID.astype(np.int), predictions], axis = 1)\n",
    "submission.columns = ['ID' , 'MaterialType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJCiVVuTQ-x6"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submit.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Copy of v01 LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
